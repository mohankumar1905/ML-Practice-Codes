{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Pytorch_Model_Formation_types.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqXVS2czgXwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkFyVLeGoyMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh9Du9UnoyRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7hp4ujooyUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_zero, train_target_zero = trainset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9SDSfZkoyXn",
        "colab_type": "code",
        "outputId": "b7064d51-d787-472f-e5b4-1d74f50d0572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(train_target_zero)#, train_image_zero"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6XhwvOCoyPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrJL8XDngjzq",
        "colab_type": "code",
        "outputId": "d58faffb-e04e-4eb8-8c75-a35b1d454cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #Inputs to hidden layer linear transformation\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    #Output Layer 10 units - One for each digit.\n",
        "    self.output = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #pass the input tensor to each of the operations.\n",
        "    x = self.hidden1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.output(x)\n",
        "    return x\n",
        "model1 = ANN()\n",
        "print(model1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANN(\n",
            "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD2rAMeJlNms",
        "colab_type": "code",
        "outputId": "705dfc7d-a054-401e-c71f-b99055c461a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#Hyperparameters for the network\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "#Building a Feed Forward Neural Network.\n",
        "model2 = nn.Sequential(nn.Linear(input_size, hidden_size[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size[0], hidden_size[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_size[1], output_size))\n",
        "print(model2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuOR26m7mtkm",
        "colab_type": "code",
        "outputId": "53328d78-34d0-47f3-911b-580a71cdf39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from collections import OrderedDict\n",
        "model3 = nn.Sequential(OrderedDict([\n",
        "                                   ('fc1', nn.Linear(input_size, hidden_size[0])),\n",
        "                                   ('relu1', nn.ReLU()),\n",
        "                                   ('fc2', nn.Linear(hidden_size[0], hidden_size[1])),\n",
        "                                   ('relu2', nn.ReLU()),\n",
        "                                   ('output', nn.Linear(hidden_size[1], output_size))\n",
        "]))\n",
        "print(model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9J4Jx1jmJxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loss Function\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "#Optimizer \n",
        "optimizer1 =  optim.SGD(model1.parameters(), lr=0.03, momentum=0.9)\n",
        "optimizer2 =  optim.SGD(model2.parameters(), lr=0.03, momentum=0.9)\n",
        "optimizer3 =  optim.SGD(model3.parameters(), lr=0.03, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6NYYTRuyqpy",
        "colab_type": "code",
        "outputId": "f067f905-661a-4962-d02f-52f07b3bd910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    #Flatten Images in 784 Long Vector\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    #Zero the Parameter Gradients\n",
        "    optimizer1.zero_grad()\n",
        "    #Forward Pass\n",
        "    output = model1(images)\n",
        "    #Determining Loss\n",
        "    loss = loss_criterion(output, labels)\n",
        "    #Backward propagation\n",
        "    loss.backward()\n",
        "    #Updating the Weights value with Optimizer Gradient\n",
        "    optimizer1.step()\n",
        "    #Print Statistics\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f\"Epoch {e} ,Training Loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 ,Training Loss: 0.07093312929762698\n",
            "Epoch 1 ,Training Loss: 0.07092298397214523\n",
            "Epoch 2 ,Training Loss: 0.07092627833785016\n",
            "Epoch 3 ,Training Loss: 0.07094359773594433\n",
            "Epoch 4 ,Training Loss: 0.0709316171169567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVzYXZ3PyuKy",
        "colab_type": "code",
        "outputId": "abaeaa44-9b71-404e-c487-93b707bf707b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    #Flatten Images in 784 Long Vector\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    #Zero the Parameter Gradients\n",
        "    optimizer2.zero_grad()\n",
        "    #Forward Pass\n",
        "    output = model2(images)\n",
        "    #Determining Loss\n",
        "    loss = loss_criterion(output, labels)\n",
        "    #Backward propagation\n",
        "    loss.backward()\n",
        "    #Updating the Weights value with Optimizer Gradient\n",
        "    optimizer2.step()\n",
        "    #Print Statistics\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f\"Epoch {e} ,Training Loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 ,Training Loss: 0.36229515008961977\n",
            "Epoch 1 ,Training Loss: 0.1672593816262938\n",
            "Epoch 2 ,Training Loss: 0.13206911872504457\n",
            "Epoch 3 ,Training Loss: 0.11324576741985\n",
            "Epoch 4 ,Training Loss: 0.09721026822814405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "352D4POK3SwD",
        "colab_type": "code",
        "outputId": "aa8b277d-3bf1-4cb2-8763-9bae40afe303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    #Flatten Images in 784 Long Vector\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    #Zero the Parameter Gradients\n",
        "    optimizer3.zero_grad()\n",
        "    #Forward Pass\n",
        "    output = model3(images)\n",
        "    #Determining Loss\n",
        "    loss = loss_criterion(output, labels)\n",
        "    #Backward propagation\n",
        "    loss.backward()\n",
        "    #Updating the Weights value with Optimizer Gradient\n",
        "    optimizer3.step()\n",
        "    #Print Statistics\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f\"Epoch {e} ,Training Loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 ,Training Loss: 0.35075934372468986\n",
            "Epoch 1 ,Training Loss: 0.16914509085298918\n",
            "Epoch 2 ,Training Loss: 0.13273395632784854\n",
            "Epoch 3 ,Training Loss: 0.11268725900648674\n",
            "Epoch 4 ,Training Loss: 0.0988305224530669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVcVgXSZ82oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Class Models to the Directory\n",
        "M1_PATH = '/content/drive/My Drive/Pytorch/model1.pkl'\n",
        "torch.save(model1.state_dict(), M1_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "765jgLPAA3Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Sequentail Models to the Directory\n",
        "M2_PATH = '/content/drive/My Drive/Pytorch/model2.pkl'\n",
        "torch.save(model2.state_dict(), M2_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YseQ20QtG2sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving Ordered Sequentail Models to the Directory\n",
        "M3_PATH = '/content/drive/My Drive/Pytorch/model3.pkl'\n",
        "torch.save(model3.state_dict(), M3_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EO3BIHHC_wA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0929cc52-2256-4046-9387-d7163833399d"
      },
      "source": [
        "model1 = ANN()\n",
        "model1.load_state_dict(torch.load(M1_PATH))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6RMV3oRHWsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f3f72ce7-f884-4efa-dea3-d2e10b8dedb0"
      },
      "source": [
        "model2.load_state_dict(torch.load(M2_PATH))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J571M3L2HcjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cc1e371d-fdce-44aa-a29f-0ea0ae284ca9"
      },
      "source": [
        "model3.load_state_dict(torch.load(M3_PATH))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ2JnpWMHg_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predcition\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRfG8ccQIBrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3f0b660-2de9-4c0b-8fa0-d136881c8b0d"
      },
      "source": [
        "len(testset)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkRQPG4CIEWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "717a6e97-daba-47e2-f4c7-d5f3bd128641"
      },
      "source": [
        "testset[0][0].shape"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjYtqmmaLdR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVhyjR09J5o6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "115ecbcf-70e9-4532-8d8d-5f894117e8ae"
      },
      "source": [
        "m1_correct = 0\n",
        "m2_correct = 0\n",
        "m3_correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in testloader:\n",
        "    #Flatten Images in 784 Long Vector\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    # Store Output\n",
        "    m1_output = model1(images)\n",
        "    m2_output = model2(images)\n",
        "    m3_output = model3(images)\n",
        "\n",
        "    _, predicted1 = torch.max(m1_output, 1)\n",
        "    _, predicted2 = torch.max(m2_output, 1)\n",
        "    _, predicted3 = torch.max(m3_output, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    m1_correct += (predicted1 == labels).sum().item()\n",
        "    m2_correct += (predicted2 == labels).sum().item()\n",
        "    m3_correct += (predicted3 == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the Model1 on the 10000 test images: {(100*m1_correct)/total}')\n",
        "print(f'Accuracy of the Model2 on the 10000 test images: {(100*m2_correct)/total}')\n",
        "print(f'Accuracy of the Model3 on the 10000 test images: {(100*m3_correct)/total}')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Model1 on the 10000 test images: 97.08\n",
            "Accuracy of the Model2 on the 10000 test images: 96.77\n",
            "Accuracy of the Model3 on the 10000 test images: 96.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ztWQ80XPIGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}