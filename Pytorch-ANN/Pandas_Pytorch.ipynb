{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qofIPC_cbVwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9SjK738cCMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Deep Learning/pima-indians-diabetes-database/diabetes.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItsiKh-_eYtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "bf34dfe0-599a-4fd0-a24c-d059787d8710"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e95MJ9tpONd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset.drop('Outcome', axis=1), dataset[['Outcome']], test_size=0.2, random_state=1994)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzflxZLNba5Z",
        "colab_type": "code",
        "outputId": "b229d2a6-cf81-419f-bd83-30fc7cffdca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# creating tensor from pandas \n",
        "train_tensor_input = torch.tensor(x_train.values.astype(np.float32))\n",
        "train_tensor_output = torch.tensor(y_train.values.astype(np.float32))\n",
        "test_tensor_input = torch.tensor(x_test.values.astype(np.float32))\n",
        "test_tensor_output = torch.tensor(y_test.values.astype(np.float32))\n",
        "# printing output tensor result\n",
        "print(train_tensor_input.shape, train_tensor_output.shape, test_tensor_input.shape, test_tensor_output.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([614, 8]) torch.Size([614, 1]) torch.Size([154, 8]) torch.Size([154, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKFCdQvIjYvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "#Taking Data from Tensor into DataLoader Function pytorch\n",
        "train_tensor = TensorDataset(train_tensor_input, train_tensor_output) \n",
        "train_loader = DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "#Taking Data from Tensor into DataLoader Function pytorch\n",
        "test_tensor = TensorDataset(test_tensor_input, test_tensor_output) \n",
        "test_loader = DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwoJBWKpbhHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "e3a266a7-7acf-47d2-cda8-71ebfe2b5d90"
      },
      "source": [
        "#Model\n",
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #Inputs to hidden layer 1 linear transformation\n",
        "    self.hidden1 = nn.Linear(8, 13)\n",
        "    #Inputs to hidden layer 2 linear transformation\n",
        "    self.hidden2 = nn.Linear(13, 10)\n",
        "    #Inputs to hidden layer 3 linear transformation\n",
        "    self.hidden3 = nn.Linear(10, 7)\n",
        "    #Output Layer 10 units - One for each digit.\n",
        "    self.output = nn.Linear(7, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #pass the input tensor to each of the operations.\n",
        "    x = self.hidden1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.hidden3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.output(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    return x\n",
        "MLP = ANN()\n",
        "print(MLP)\n",
        "#Loss Criterion\n",
        "loss_criterion = nn.BCELoss()\n",
        "#Optimizer \n",
        "optimizer = optim.Adam(MLP.parameters(), lr=0.0001)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANN(\n",
            "  (hidden1): Linear(in_features=8, out_features=13, bias=True)\n",
            "  (hidden2): Linear(in_features=13, out_features=10, bias=True)\n",
            "  (hidden3): Linear(in_features=10, out_features=7, bias=True)\n",
            "  (output): Linear(in_features=7, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVjCR0rPi1Ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bf3aef0-1f98-4942-e4bd-c6c155f4ce63"
      },
      "source": [
        "epochs = 1000\n",
        "lowest_validation_loss = None\n",
        "model_save_path = '/content/drive/My Drive/Pytorch/MLP.pt'\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for train_inputs, train_labels in train_loader:\n",
        "    #Setting the Gradients to Zero\n",
        "    optimizer.zero_grad()\n",
        "    #Forward Pass\n",
        "    train_outputs = MLP(train_inputs)\n",
        "    #Loss Calculation\n",
        "    loss = loss_criterion(train_outputs, train_labels)\n",
        "    #Backward Propagation\n",
        "    loss.backward()\n",
        "    #Updating Gradients\n",
        "    optimizer.step()\n",
        "    #Cost Calculation\n",
        "    running_loss+=loss.item()\n",
        "  else:\n",
        "    with torch.no_grad():\n",
        "      validation_loss = loss_criterion(MLP(test_tensor_input), test_tensor_output)\n",
        "      if (lowest_validation_loss is None) or (validation_loss < lowest_validation_loss):\n",
        "        lowest_validation_loss = validation_loss.item()\n",
        "        #Saving Model weigths with lowest validation loss\n",
        "        print(f'Epoch {e} Training Loss: {running_loss/(len(train_loader))}, Validation Loss: {validation_loss}')\n",
        "        torch.save(MLP.state_dict(), model_save_path)\n",
        "    if e%10==0:\n",
        "      print(f'Epoch {e} Training Loss: {running_loss/(len(train_loader))}, Validation Loss: {validation_loss}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Training Loss: 0.5568173546944896, Validation Loss: 0.6412449479103088\n",
            "Epoch 0 Training Loss: 0.5568173546944896, Validation Loss: 0.6412449479103088\n",
            "Epoch 1 Training Loss: 0.552263508881292, Validation Loss: 0.640596866607666\n",
            "Epoch 3 Training Loss: 0.5533356729053682, Validation Loss: 0.6397342085838318\n",
            "Epoch 4 Training Loss: 0.5488434650244252, Validation Loss: 0.6392588019371033\n",
            "Epoch 5 Training Loss: 0.5508482162990878, Validation Loss: 0.6389068365097046\n",
            "Epoch 6 Training Loss: 0.550665317523864, Validation Loss: 0.6387301087379456\n",
            "Epoch 8 Training Loss: 0.5460995195373413, Validation Loss: 0.6363465189933777\n",
            "Epoch 10 Training Loss: 0.54779392625055, Validation Loss: 0.6380131840705872\n",
            "Epoch 16 Training Loss: 0.5455033250393406, Validation Loss: 0.6360687613487244\n",
            "Epoch 20 Training Loss: 0.5422039176187208, Validation Loss: 0.6399686336517334\n",
            "Epoch 27 Training Loss: 0.5424612885521304, Validation Loss: 0.6356171369552612\n",
            "Epoch 30 Training Loss: 0.5417568015475427, Validation Loss: 0.638320803642273\n",
            "Epoch 40 Training Loss: 0.5346124816325403, Validation Loss: 0.6372979879379272\n",
            "Epoch 49 Training Loss: 0.5354802870462018, Validation Loss: 0.6355431079864502\n",
            "Epoch 50 Training Loss: 0.5325644763727342, Validation Loss: 0.6332055926322937\n",
            "Epoch 50 Training Loss: 0.5325644763727342, Validation Loss: 0.6332055926322937\n",
            "Epoch 60 Training Loss: 0.5323608815670013, Validation Loss: 0.63752681016922\n",
            "Epoch 70 Training Loss: 0.5267191548501292, Validation Loss: 0.6367479562759399\n",
            "Epoch 80 Training Loss: 0.5252703332131908, Validation Loss: 0.6378768086433411\n",
            "Epoch 100 Training Loss: 0.521023313364675, Validation Loss: 0.6389914155006409\n",
            "Epoch 110 Training Loss: 0.5174811549725071, Validation Loss: 0.6403695344924927\n",
            "Epoch 120 Training Loss: 0.5193561152104409, Validation Loss: 0.6384980082511902\n",
            "Epoch 130 Training Loss: 0.5152791281861644, Validation Loss: 0.6342710852622986\n",
            "Epoch 140 Training Loss: 0.5084665436898509, Validation Loss: 0.6375946402549744\n",
            "Epoch 148 Training Loss: 0.5112373261682449, Validation Loss: 0.632956326007843\n",
            "Epoch 150 Training Loss: 0.5099870552939754, Validation Loss: 0.6349362730979919\n",
            "Epoch 154 Training Loss: 0.5106873125318558, Validation Loss: 0.6328898072242737\n",
            "Epoch 160 Training Loss: 0.5058723498255976, Validation Loss: 0.6341939568519592\n",
            "Epoch 161 Training Loss: 0.5110924385728375, Validation Loss: 0.6311347484588623\n",
            "Epoch 170 Training Loss: 0.5050690798990188, Validation Loss: 0.6331178545951843\n",
            "Epoch 180 Training Loss: 0.5056416517303836, Validation Loss: 0.633741557598114\n",
            "Epoch 190 Training Loss: 0.5016301812664155, Validation Loss: 0.6342899203300476\n",
            "Epoch 200 Training Loss: 0.5014648283681562, Validation Loss: 0.6346669793128967\n",
            "Epoch 201 Training Loss: 0.49694744305264565, Validation Loss: 0.6301065683364868\n",
            "Epoch 210 Training Loss: 0.498301190474341, Validation Loss: 0.6347575783729553\n",
            "Epoch 211 Training Loss: 0.49744460875949553, Validation Loss: 0.6296539306640625\n",
            "Epoch 220 Training Loss: 0.49889960716808995, Validation Loss: 0.6301854848861694\n",
            "Epoch 221 Training Loss: 0.49565356777560327, Validation Loss: 0.6277779936790466\n",
            "Epoch 230 Training Loss: 0.4942157564143981, Validation Loss: 0.6299137473106384\n",
            "Epoch 240 Training Loss: 0.49152811664727425, Validation Loss: 0.6369295120239258\n",
            "Epoch 250 Training Loss: 0.48949391274682935, Validation Loss: 0.6344837546348572\n",
            "Epoch 260 Training Loss: 0.48649788287378126, Validation Loss: 0.6332805752754211\n",
            "Epoch 270 Training Loss: 0.48874446269004573, Validation Loss: 0.6321681141853333\n",
            "Epoch 280 Training Loss: 0.4849528043020156, Validation Loss: 0.6324783563613892\n",
            "Epoch 290 Training Loss: 0.483503760349366, Validation Loss: 0.630988597869873\n",
            "Epoch 300 Training Loss: 0.4797833162930704, Validation Loss: 0.6323281526565552\n",
            "Epoch 310 Training Loss: 0.48199427055735744, Validation Loss: 0.6362264752388\n",
            "Epoch 320 Training Loss: 0.47908216835029666, Validation Loss: 0.6337812542915344\n",
            "Epoch 324 Training Loss: 0.47610180656756124, Validation Loss: 0.6272566318511963\n",
            "Epoch 330 Training Loss: 0.4750624111583156, Validation Loss: 0.6307910084724426\n",
            "Epoch 339 Training Loss: 0.47312602208506677, Validation Loss: 0.6260867714881897\n",
            "Epoch 340 Training Loss: 0.47499590102703343, Validation Loss: 0.6378889679908752\n",
            "Epoch 350 Training Loss: 0.473534123551461, Validation Loss: 0.6375950574874878\n",
            "Epoch 358 Training Loss: 0.4710960676593165, Validation Loss: 0.6245991587638855\n",
            "Epoch 360 Training Loss: 0.47030635706840024, Validation Loss: 0.6292355060577393\n",
            "Epoch 370 Training Loss: 0.47211987501190555, Validation Loss: 0.6333948373794556\n",
            "Epoch 380 Training Loss: 0.4677255530991862, Validation Loss: 0.6296642422676086\n",
            "Epoch 390 Training Loss: 0.4658687996768182, Validation Loss: 0.6321990489959717\n",
            "Epoch 400 Training Loss: 0.46319918719030195, Validation Loss: 0.6279359459877014\n",
            "Epoch 410 Training Loss: 0.46590052256661074, Validation Loss: 0.6335878968238831\n",
            "Epoch 419 Training Loss: 0.4633486773217878, Validation Loss: 0.6222635507583618\n",
            "Epoch 420 Training Loss: 0.4635603430290376, Validation Loss: 0.6285991668701172\n",
            "Epoch 430 Training Loss: 0.46219943608007125, Validation Loss: 0.6390877962112427\n",
            "Epoch 440 Training Loss: 0.46124387195994776, Validation Loss: 0.6212256550788879\n",
            "Epoch 440 Training Loss: 0.46124387195994776, Validation Loss: 0.6212256550788879\n",
            "Epoch 450 Training Loss: 0.4571717299761311, Validation Loss: 0.6248128414154053\n",
            "Epoch 452 Training Loss: 0.45723637121339, Validation Loss: 0.6211571097373962\n",
            "Epoch 460 Training Loss: 0.4572984258974752, Validation Loss: 0.6336474418640137\n",
            "Epoch 462 Training Loss: 0.45517406949112493, Validation Loss: 0.6210836172103882\n",
            "Epoch 470 Training Loss: 0.4538952624124865, Validation Loss: 0.6261184811592102\n",
            "Epoch 480 Training Loss: 0.4550001537126879, Validation Loss: 0.6255538463592529\n",
            "Epoch 481 Training Loss: 0.4561545430652557, Validation Loss: 0.6208385825157166\n",
            "Epoch 490 Training Loss: 0.4510549958194456, Validation Loss: 0.621719241142273\n",
            "Epoch 496 Training Loss: 0.4514256461012748, Validation Loss: 0.6180565357208252\n",
            "Epoch 500 Training Loss: 0.45064702173394544, Validation Loss: 0.6203674077987671\n",
            "Epoch 510 Training Loss: 0.4501895563256356, Validation Loss: 0.6183589696884155\n",
            "Epoch 514 Training Loss: 0.4488645806427925, Validation Loss: 0.6176304817199707\n",
            "Epoch 520 Training Loss: 0.44984748022210214, Validation Loss: 0.6229948401451111\n",
            "Epoch 530 Training Loss: 0.4471304312108024, Validation Loss: 0.6182199120521545\n",
            "Epoch 540 Training Loss: 0.447518763522948, Validation Loss: 0.6239684820175171\n",
            "Epoch 550 Training Loss: 0.4463975326188149, Validation Loss: 0.6222306489944458\n",
            "Epoch 554 Training Loss: 0.4481243897349604, Validation Loss: 0.6140217185020447\n",
            "Epoch 560 Training Loss: 0.4441115089481877, Validation Loss: 0.6239016056060791\n",
            "Epoch 570 Training Loss: 0.4453991973592389, Validation Loss: 0.6235986948013306\n",
            "Epoch 580 Training Loss: 0.443506411246715, Validation Loss: 0.6194772124290466\n",
            "Epoch 590 Training Loss: 0.4392978814580748, Validation Loss: 0.6225364208221436\n",
            "Epoch 600 Training Loss: 0.4363006576895714, Validation Loss: 0.6174476146697998\n",
            "Epoch 608 Training Loss: 0.43670534486732177, Validation Loss: 0.6126787662506104\n",
            "Epoch 610 Training Loss: 0.44016928802574834, Validation Loss: 0.6293101906776428\n",
            "Epoch 620 Training Loss: 0.4379534322407938, Validation Loss: 0.6200319528579712\n",
            "Epoch 630 Training Loss: 0.43692471735900446, Validation Loss: 0.6216269135475159\n",
            "Epoch 640 Training Loss: 0.434844140804583, Validation Loss: 0.6299195289611816\n",
            "Epoch 650 Training Loss: 0.4340910947611255, Validation Loss: 0.6196479201316833\n",
            "Epoch 654 Training Loss: 0.4479536922468293, Validation Loss: 0.6090890765190125\n",
            "Epoch 660 Training Loss: 0.43094471409436197, Validation Loss: 0.6186757683753967\n",
            "Epoch 670 Training Loss: 0.43332550193994274, Validation Loss: 0.6297503113746643\n",
            "Epoch 680 Training Loss: 0.43063842096636373, Validation Loss: 0.622927188873291\n",
            "Epoch 690 Training Loss: 0.42896464731424083, Validation Loss: 0.6126235127449036\n",
            "Epoch 697 Training Loss: 0.4362014373463969, Validation Loss: 0.607539713382721\n",
            "Epoch 700 Training Loss: 0.4303274022475366, Validation Loss: 0.6131137609481812\n",
            "Epoch 710 Training Loss: 0.4325099289417267, Validation Loss: 0.6140413880348206\n",
            "Epoch 720 Training Loss: 0.42658518206688667, Validation Loss: 0.6052002906799316\n",
            "Epoch 720 Training Loss: 0.42658518206688667, Validation Loss: 0.6052002906799316\n",
            "Epoch 730 Training Loss: 0.4270470123137197, Validation Loss: 0.6167612075805664\n",
            "Epoch 740 Training Loss: 0.4234222892311312, Validation Loss: 0.6138789653778076\n",
            "Epoch 750 Training Loss: 0.4287108747709182, Validation Loss: 0.6253215670585632\n",
            "Epoch 760 Training Loss: 0.42397275927566713, Validation Loss: 0.6073612570762634\n",
            "Epoch 770 Training Loss: 0.42190511500643146, Validation Loss: 0.6190154552459717\n",
            "Epoch 780 Training Loss: 0.423320030493121, Validation Loss: 0.6060742735862732\n",
            "Epoch 784 Training Loss: 0.4231207165266237, Validation Loss: 0.6038966178894043\n",
            "Epoch 790 Training Loss: 0.41877170471895125, Validation Loss: 0.6212332844734192\n",
            "Epoch 800 Training Loss: 0.42032920449010786, Validation Loss: 0.6067968010902405\n",
            "Epoch 810 Training Loss: 0.4195403572051756, Validation Loss: 0.6118455529212952\n",
            "Epoch 820 Training Loss: 0.4180661545645806, Validation Loss: 0.6199805736541748\n",
            "Epoch 830 Training Loss: 0.4164932449498484, Validation Loss: 0.6095948219299316\n",
            "Epoch 840 Training Loss: 0.4161834668728613, Validation Loss: 0.6063219308853149\n",
            "Epoch 850 Training Loss: 0.41764522536147025, Validation Loss: 0.6051125526428223\n",
            "Epoch 858 Training Loss: 0.41277234472574725, Validation Loss: 0.6020336151123047\n",
            "Epoch 860 Training Loss: 0.4158115840006259, Validation Loss: 0.612228512763977\n",
            "Epoch 870 Training Loss: 0.41263165913762584, Validation Loss: 0.609004020690918\n",
            "Epoch 873 Training Loss: 0.4193228032560118, Validation Loss: 0.5995023846626282\n",
            "Epoch 880 Training Loss: 0.4123021215200424, Validation Loss: 0.6066688895225525\n",
            "Epoch 890 Training Loss: 0.41019385235924877, Validation Loss: 0.6116347312927246\n",
            "Epoch 900 Training Loss: 0.4139887952516156, Validation Loss: 0.6125063896179199\n",
            "Epoch 910 Training Loss: 0.4096210025731594, Validation Loss: 0.605563223361969\n",
            "Epoch 920 Training Loss: 0.408026424386809, Validation Loss: 0.6107868552207947\n",
            "Epoch 930 Training Loss: 0.4132279013433764, Validation Loss: 0.6112734079360962\n",
            "Epoch 940 Training Loss: 0.4092065643879675, Validation Loss: 0.6191946268081665\n",
            "Epoch 950 Training Loss: 0.41044213839115634, Validation Loss: 0.608111560344696\n",
            "Epoch 960 Training Loss: 0.4050939674338987, Validation Loss: 0.6187559366226196\n",
            "Epoch 970 Training Loss: 0.4036944900308886, Validation Loss: 0.6138747930526733\n",
            "Epoch 980 Training Loss: 0.4044231234058257, Validation Loss: 0.6103206276893616\n",
            "Epoch 990 Training Loss: 0.40387628924462105, Validation Loss: 0.6048890352249146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8bsf678tCLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1acb650d-00d1-4a65-a3e5-435883ac62d9"
      },
      "source": [
        "#Load the saved model path\n",
        "MLP.load_state_dict(torch.load(model_save_path))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbIl-SE_GT-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "d614f5cd-a55c-45da-f668-6aad221c7ab4"
      },
      "source": [
        "with torch.no_grad():\n",
        "  prediction = MLP(test_tensor_input)\n",
        "  print(roc_auc_score(test_tensor_output, prediction))\n",
        "  #Threshold Evaluator\n",
        "  prediction[prediction>0.5]=1\n",
        "  prediction[prediction<=0.5]=0\n",
        "  print(accuracy_score(test_tensor_output, prediction))\n",
        "  print(classification_report(test_tensor_output, prediction))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7305976806422837\n",
            "0.6948051948051948\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.82      0.77        95\n",
            "         1.0       0.63      0.49      0.55        59\n",
            "\n",
            "    accuracy                           0.69       154\n",
            "   macro avg       0.68      0.66      0.66       154\n",
            "weighted avg       0.69      0.69      0.69       154\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MerHG915JjMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "c10674a1-b969-43e9-e1ab-349e4c6a0607"
      },
      "source": [
        "#Keras Model to Compare\n",
        "# Create first network with Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(13,input_dim=8,init='uniform',activation='relu'))\n",
        "model.add(Dense(10,init='uniform',activation='relu'))\n",
        "model.add(Dense(7,init='uniform',activation='relu'))\n",
        "model.add(Dense(1,init='uniform',activation='sigmoid'))\n",
        "#Compile model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "#Fit the model\n",
        "model.fit(x_train,y_train,nb_epoch=1000,batch_size=10, validation_data=[x_test, y_test])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}